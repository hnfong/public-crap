# Consciousness as a social construct

When people talk about "consciousness" they are usually talking about two things: (a) objective consciousness, and/or (b) subjective consciousness.

These are terminology I use to separate concepts that tend to confuse people.

"Objective consciousness" is something that can be objectively measured, like whether somebody responds when you call their name, whether they say "ouch" when you pinch them, basically whether they respond reasonably to external stimuli. Note that "philosophical zombies" [1] are considered "objectively conscious" under this definition.

"Subjective consciousness" is the more controversial part. How do we know that somebody is "really" conscious and "really" feeling the experience, instead of "merely" being a complicated automaton, a "soulless" machine that is simply programmed to react to sensory inputs? This is what trips people up.

For reasons that eludes me, Western philosophy has invested much time and resources on trying to prove that (1) all humans are conscious beings and (2) other animals are generally not. They seem to think that this could excuse us, on a moral level, of things like raising billions of animals just to slaughter them and eat their meat. By claiming that animals mostly don't "feel" the pain and so it's OK to have steak.

Of course this sounds totally ridiculous from the perspective of many Eastern philosophy traditions. Personally, I suspect the tradition of Western philosophy has made discussing the issue of "consciousness" much harder than it needs to be, since there is really no known scientific way one can qualitatively separate humans from the animals we eat. As long as the question of "consciousness" is somehow morally tied to the question of "can we do horrible things to 'it'?", one cannot have honest discussions about these philosophical topics without having to navigate political-correctness-landmines.

So, we're not going to do that here. We're not going to force ourselves to try to conclude that humans are "subjectively conscious", because that conclusion should not inform us whether we, for example, are morally allowed to do hurtful things to another person.

So then, how do we tell whether somebody who is acting "objectively conscious" is also "subjectively conscious"? The answer is, we don't. And we don't need to. Once liberated from the shackles of Western philosophy traditions, one could immediately observe that, as far as scientific principles are observed, we cannot make any claims at all about subjective consciousness. We may vehemently believe that we ourselves are subjectively conscious, but we cannot prove anything to an dispassionate observer that we "really feel" whatever we claim to be feeling.

The only way to communicate is to assume the other party is a similar being to ourselves, and by analogy and empathy would understand and agree that the subjective experiences are real. This is a *social construct*, a *social protocol*, i.e. "you accept that I'm conscious, I will accept that you are too". In this way, it is something like a virtue, eg. honesty, courtesy, etc. I believe this is most likely hard-coded social behavior of animals (including humans), not something that can be studied scientifically (unless you're doing "social science").

But if the "assumption of subjective consciousness between peers" is a social construct, what does it mean for my personal conscious feelings and thoughts? I would say they are *also* social constructs. As ridiculous as it sounds, I don't believe I have conclusive evidence that my pain is "real" when I prick myself with a needle. The "philosophical zombie" problem applies to myself as well, with a slight twist -- my brain can access its own internal state. 

My brain, being one of the world's best learning machines, has learned that some stimuli would affect some internal states, which would then cause my body to produce reactions of pain, anger and fear. It has also learned that those stimuli and internal states are also causally related to social reactions (from other people) of pain, anger and fear. Subjective pain is at least partially a social construct. I wonder whether it can exist in a "purely subjective" form. Can we really feel any "purely subjective" pain that would be totally causally unrelated to my outward behavior? One may attempt to endure the pain and act as if one does not feel anything, but even the mental strain of suppressing the subjective experience would cause a slight change in cognitive behavior. It affects mood, memories, etc. And thus, there is no "pure pain". The only reason people used to posit the existence of purely subjective experiences is because we did not have access to internal brain states. But now we do.

So, when we discover neurons in a person that are causally related to painful feelings, do we consider this an "objective" or "subjective" type of consciousness? I don't think it really matters. If the former (because we can objective observe these internal states that seem to be connected to subjective experiences), then I claim that purely subjective experiences don't exist. We are all "philosophical zombies", not even the real-est of real subjective experiences would change that. For all we know about neuroscience, all subjective experiences are generated from electrical impulses in neurons that mostly reside in our brain. On the other hand, if the latter, then... great! We've solved a profound(?) philosophical puzzle by shuffling some terminology around (given some advanced understanding of neuroscience).

Of course, this doesn't explain the greatest mystery -- why the hell do we "experience" what we experience? I believe the state of art explanation is that this "experiencer" (which we also often refer to as "consciousness") is a "meta" layer of the brain that inspects its own internal states. It seems to be a "program" that scans internal states and triggers the body to do things according to a learning model. And yet while this theory is great for those who intend to create artificial consciousnesses, inventing metaphysical "meta" layers on feedback systems seem to be another kind of dualism under which meta layers aren't that different from spirits and ghosts. Are we prepared to posit that sufficiently complicated feedback systems (regardless of form) are all conscious? I suppose some philosophies accept this conclusion but I don't think any socially-acceptable philosophy knows what to make of a conclusion like "actually ant colonies as a system are conscious" or "actually the ecosystem of the Earth is a huge conscious being" or even "human societies are conscious" (liquidators are actually murderer of companies! who'd have thought).

All this being said, I must re-iterate my cynical view that while all this discussion is fascinating (for me) philosophically, any attempts to make a moral story out of philosophy of consciousness (and I might add, intelligence) is probably a wrong thing to do. Much motivation to understand consciousness (and I might add, intelligence) is, really, a vain exercise in trying to abstract and generalize our own "form", trying to define what makes us special, trying to capture the things that we prize as the subject of our pride. And yet, beyond our vain social constructs and protocols, these things don't really mean a thing.

[1] https://en.wikipedia.org/wiki/Philosophical_zombie

