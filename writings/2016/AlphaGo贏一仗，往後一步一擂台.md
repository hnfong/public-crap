# AlphaGo贏一仗，往後一步一擂台

AlphaGo 打贏九段棋手，其實最重要嘅結果，唔係「電腦叻過人腦喇」，而係「哇屌原來呢啲 Monte Carlo Tree Search / Convolutional neural network 加埋勁多 computing power，真係打得贏九段棋手架！」

人工智能啲技術同（高階）原理其實都存在咗好耐，唔係啲咩新嘢。早排同某醫管局員工吹水，佢話中學時佢試過整蘋果棋 AI，用 genetic algorithm 去「自己同自己對戰」，調整（i.e. “learn”）戰術。佢話最後自己都捉唔贏個 AI，但當然我唔知佢玩蘋果棋有幾勁啦。（我自己就寫完個過三關 minimax 之後就放棄咗，哈哈哈）

要用人工智能做啲「勁」嘅結果出嚟，你遇到個問題反而係，坊間嘅「招數」太多，就算你識晒啲「招數」都未必識得好好咁應用。例如當年深藍打贏國際象棋冠軍，用嘅「招數」同今次 AlphaGo 用嘅唔同，因為圍棋同象棋嘅特性唔同，所以需要用嘅「招數」都唔同。

人工智能個核心問題係好 paradoxical 嘅：本來人工智能個目的就係令電腦可以 somehow 「自學」，唔使人類「教」佢都識。如果你可以好清楚咁解釋點解部電腦識得XXX，咁只不過係你「填鴨」教佢嘅嘢嚟啫，邊度算係勁勁嘅「人工智能」？ 相反，如果你唔知點解佢 work，咁⋯⋯⋯你又點知佢會 work 呢？

所以任何嶄新嘅人工智能突破，唔係靠「先有理論證明，之後再應用」呢類「數學推論」，而係靠摸著石頭過河，靠「先鳩估，再試下某幾招夾埋 work 唔 work」嘅「科學方法」。我好肯定，Google Deepmind 團隊喺佢哋開始 AlphaGo 呢個項目之前，唔會知道佢哋呢啲「Monte Carlo Tree Search」、「Convolutional Neural Network」等等嘅「招式」有幾使得。甚至佢哋一開始未必係用呢幾招添，可能係試過其他招冇效，所以放棄咗。只有透過同人類對戰，大家先知道呢啲招有冇用。呢啲係實實在在嘅 empirical observation 嚟。我哋一方面觀察到某啲人類智能招式有幾勁，同時間，我哋亦都可以觀察到人類嘅智慧有幾「深」。我哋可以 somehow 靠電腦「量化」人類嘅智慧，去量度頂尖棋手嘅「智慧」。即係如果一個 2000 個 CPU 300 個 GPU 嘅電腦可以打贏你，咁你都唔係好很勁啫係咪？ :) （講笑咋⋯我一粒 CPU 都打唔過）

當然幾盤棋嘅資料係唔夠我哋作出任何科學結論。但如果 AlphaGo 繼續同九段棋手對戰，而且仲可以勝出，咁我哋就可以得出一個科學結論，原來「圍棋」呢個遊戲需要嘅「智慧程度」，走唔出 AlphaGo 所使用嗰幾招。

人類係自大嘅。自從 Alan Turing 發表論文提出「Can machines think?」呢個問題之後，哲學界就對此爭論不斷。每當電腦解決一個問題之後，自大嘅人類就會話：「唓，你個程式只不過係咁咁咁之嘛，邊度算係真正嘅人工智能呢？如果你解決到 XXX 問題，咁我就話你叻喇！」 1997 年深藍勝出之後，人類就搬圍棋出嚟，話象棋咁「容易」，電腦打贏圍棋高手先算係勁。唔知下一個「龍門」會喺邊呢？

其實就算電腦技術、人工智能發展到咩地步，都會有人質疑嗰啲算唔算係「真正嘅智慧」。講到尾，都係嗰個 paradox：如果你解釋到電腦點 solve 個問題，咁就唔算「人工智能」，只係「填鴨」式編程；如果你解釋唔到，咁你又點樣砌嗰嚿嘢出嚟？

人類係自大嘅。人類唔相信自己嘅「智慧」可以憑空用廢銅爛鐵複製出嚟，相信自己係地球獨一無二嘅智慧生物。所以世上出現一個可以喺某啲遊戲入面打贏人類嘅電腦，自大嘅人類就會覺得驚慌。但我唔驚。最後人類如果整到一個「真．人工智能」，咁我哋就可以通過呢個 AI 去了解「自己」。人工智能每征服一個範疇，其實人類就對「自己」理解多啲，就會明白原來自己「無窮嘅智商」，可能只不過係幾千粒 CPU 都可以複製嘅嘢嚟。

知道自己智慧嘅上限，我哋就學識謙遜。

（原文於 2016 年 3 月發佈，略有修輯）
